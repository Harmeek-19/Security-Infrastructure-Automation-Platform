# vulnerability/risk_scoring.py

from typing import Dict, List, Union
import math
from datetime import datetime, timezone
from .models import Vulnerability, NucleiFinding
from reconnaissance.models import Service

class RiskScorer:
    def __init__(self):
        # Base weights for different components
        self.weights = {
            'cvss': 0.4,
            'exposure': 0.2,
            'business_impact': 0.2,
            'exploitability': 0.2
        }
        
        # Severity base scores
        self.severity_scores = {
            'CRITICAL': 10.0,
            'HIGH': 8.0,
            'MEDIUM': 5.0,
            'LOW': 2.0,
            'INFO': 0.5
        }
        
        # Exploitability factors
        self.exploitability_factors = {
            'public_exploit': 2.0,
            'authentication_required': 0.8,
            'complex_exploit': 0.6
        }

    def calculate_risk_score(self, vulnerability: Union[Vulnerability, NucleiFinding]) -> float:
        """Calculate comprehensive risk score"""
        cvss_component = self._calculate_cvss_component(vulnerability)
        exposure_component = self._calculate_exposure_component(vulnerability)
        business_impact = self._calculate_business_impact(vulnerability)
        exploitability = self._calculate_exploitability(vulnerability)
        
        # Weight and combine components
        final_score = (
            cvss_component * self.weights['cvss'] +
            exposure_component * self.weights['exposure'] +
            business_impact * self.weights['business_impact'] +
            exploitability * self.weights['exploitability']
        )
        
        # Normalize to 0-10 scale
        return round(min(max(final_score, 0), 10), 2)

    def _calculate_cvss_component(self, vulnerability: Union[Vulnerability, NucleiFinding]) -> float:
        """Calculate CVSS-based component"""
        if hasattr(vulnerability, 'cvss_score') and vulnerability.cvss_score:
            return float(vulnerability.cvss_score)
        
        # Use severity as fallback
        return self.severity_scores.get(vulnerability.severity, 0.0)

    def _calculate_exposure_component(self, vulnerability: Union[Vulnerability, NucleiFinding]) -> float:
        """Calculate exposure based on various factors"""
        exposure_score = 5.0  # Base score
        
        # Check if the vulnerability is on a public-facing service
        if hasattr(vulnerability, 'target'):
            services = Service.objects.filter(host=vulnerability.target)
            for service in services:
                if service.port in [80, 443, 8080, 8443]:  # Web services
                    exposure_score += 2.0
                elif service.port < 1024:  # Well-known ports
                    exposure_score += 1.0
                    
        # Age factor (older vulnerabilities are higher risk)
        age_in_days = (datetime.now(timezone.utc) - vulnerability.discovery_date).days
        age_factor = min(age_in_days / 30, 3.0)  # Cap at 3x after 90 days
        exposure_score *= (1 + (age_factor * 0.1))
        
        return min(exposure_score, 10.0)

    def _calculate_business_impact(self, vulnerability: Union[Vulnerability, NucleiFinding]) -> float:
        """Calculate business impact score"""
        impact_score = 5.0  # Base score
        
        # Check for critical keywords in vulnerability name/description
        critical_terms = ['credentials', 'password', 'admin', 'authentication', 'sensitive', 'data breach']
        description = getattr(vulnerability, 'description', '').lower()
        name = getattr(vulnerability, 'name', '').lower()
        
        for term in critical_terms:
            if term in description or term in name:
                impact_score += 1.0
                
        # Adjust based on vulnerability type
        if hasattr(vulnerability, 'vuln_type'):
            high_impact_types = ['rce', 'sqli', 'cmdi', 'ssrf']
            if vulnerability.vuln_type.lower() in high_impact_types:
                impact_score += 2.0
                
        return min(impact_score, 10.0)

    def _calculate_exploitability(self, vulnerability: Union[Vulnerability, NucleiFinding]) -> float:
        """Calculate exploitability score"""
        exploitability_score = 5.0  # Base score
        
        # Check metadata for exploit information
        if hasattr(vulnerability, 'metadata'):
            metadata = vulnerability.metadata
            if metadata.get('has_exploit', False):
                exploitability_score *= self.exploitability_factors['public_exploit']
            if metadata.get('authentication_required', False):
                exploitability_score *= self.exploitability_factors['authentication_required']
            if metadata.get('complex_exploit', False):
                exploitability_score *= self.exploitability_factors['complex_exploit']
        
        # Check references for exploit-db or similar
        if hasattr(vulnerability, 'references'):
            references = vulnerability.references
            if any('exploit-db' in ref.lower() for ref in references):
                exploitability_score *= self.exploitability_factors['public_exploit']
                
        return min(exploitability_score, 10.0)

    def calculate_target_risk_score(self, target: str) -> Dict:
        """Calculate overall risk score for a target"""
        vulnerabilities = list(Vulnerability.objects.filter(target=target))
        nuclei_findings = list(NucleiFinding.objects.filter(target=target))
        
        all_findings = vulnerabilities + nuclei_findings
        if not all_findings:
            return {
                'target': target,
                'overall_risk_score': 0.0,
                'total_findings': 0,
                'risk_breakdown': {
                    'critical': 0,
                    'high': 0,
                    'medium': 0,
                    'low': 0,
                    'info': 0
                },
                'top_risks': []
            }
            
        # Calculate individual risk scores
        risk_scores = []
        severity_counts = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0, 'INFO': 0}
        
        for finding in all_findings:
            risk_score = self.calculate_risk_score(finding)
            severity_counts[finding.severity] += 1
            risk_scores.append({
                'finding': finding,
                'score': risk_score
            })
            
        # Sort by risk score
        risk_scores.sort(key=lambda x: x['score'], reverse=True)
        
        # Calculate overall risk score (weighted average)
        total_weight = sum(score['score'] for score in risk_scores)
        if total_weight > 0:
            overall_score = sum(score['score'] ** 2 for score in risk_scores) / total_weight
        else:
            overall_score = 0
            
        # Get top 5 risks
        top_risks = []
        for risk in risk_scores[:5]:
            finding = risk['finding']
            top_risks.append({
                'name': finding.name,
                'severity': finding.severity,
                'risk_score': risk['score'],
                'type': finding.__class__.__name__
            })
            
        return {
            'target': target,
            'overall_risk_score': round(overall_score, 2),
            'total_findings': len(all_findings),
            'risk_breakdown': severity_counts,
            'top_risks': top_risks
        }

    def calculate_asset_criticality(self, target: str) -> float:
        """Calculate asset criticality score"""
        criticality_score = 5.0  # Base score
        
        # Check for critical services
        services = Service.objects.filter(host=target)
        for service in services:
            if service.name.lower() in ['http', 'https', 'ssh', 'ftp', 'database']:
                criticality_score += 1.0
            if service.category == 'database':
                criticality_score += 2.0
                
        # Check for sensitive information exposure
        high_risk_vulns = Vulnerability.objects.filter(
            target=target,
            severity__in=['CRITICAL', 'HIGH']
        ).count()
        
        criticality_score += min(high_risk_vulns * 0.5, 3.0)
        
        return min(criticality_score, 10.0)

    def get_risk_trends(self, target: str, days: int = 30) -> Dict:
        """Get risk score trends over time"""
        from django.utils import timezone
        from datetime import timedelta
        
        start_date = timezone.now() - timedelta(days=days)
        
        # Get vulnerabilities and findings within the time range
        vulnerabilities = Vulnerability.objects.filter(
            target=target,
            discovery_date__gte=start_date
        ).order_by('discovery_date')
        
        nuclei_findings = NucleiFinding.objects.filter(
            target=target,
            discovery_date__gte=start_date
        ).order_by('discovery_date')
        
        # Calculate daily risk scores
        daily_scores = {}
        for vuln in vulnerabilities:
            date = vuln.discovery_date.date()
            if date not in daily_scores:
                daily_scores[date] = []
            daily_scores[date].append(self.calculate_risk_score(vuln))
            
        for finding in nuclei_findings:
            date = finding.discovery_date.date()
            if date not in daily_scores:
                daily_scores[date] = []
            daily_scores[date].append(self.calculate_risk_score(finding))
            
        # Calculate average daily scores
        trend_data = []
        for date in sorted(daily_scores.keys()):
            trend_data.append({
                'date': date.isoformat(),
                'average_risk_score': round(sum(daily_scores[date]) / len(daily_scores[date]), 2),
                'findings_count': len(daily_scores[date])
            })
            
        return {
            'target': target,
            'period_days': days,
            'trend_data': trend_data
        }