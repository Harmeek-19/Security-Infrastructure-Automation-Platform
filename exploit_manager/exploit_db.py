# File: exploit_manager/exploit_db.py
# Updated implementation to handle exploit synchronization correctly

import requests
import csv
import io
import json
import logging
import time
from datetime import datetime
from django.conf import settings
from django.utils import timezone  # Import timezone for timezone-aware datetimes
from django.db.models import Max
from .models import Exploit, ExploitSource

logger = logging.getLogger(__name__)

class ExploitDBManager:
    """Manages interaction with ExploitDB"""
    
    # ExploitDB CSV URL
# To:
    EXPLOITDB_CSV_URL = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv"
    EXPLOITDB_RAW_URL = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/exploits"
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.source, _ = ExploitSource.objects.get_or_create(
            name="ExploitDB",
            defaults={
                'description': "Offensive Security's Exploit Database Archive",
                'api_url': self.EXPLOITDB_CSV_URL,
                'is_active': True
            }
        )
    
    def search_exploits(self, query: str = None, cve: str = None, platform: str = None, 
                         exploit_type: str = None, limit: int = 100) -> list:
        """
        Search for exploits in ExploitDB based on various criteria
        
        Args:
            query: General search query
            cve: Specific CVE ID to search for
            platform: Platform filter (e.g., 'windows', 'linux')
            exploit_type: Type filter (e.g., 'webapps', 'remote', 'local')
            limit: Maximum number of results to return
            
        Returns:
            List of exploit dictionaries
        """
        try:
            # Download the CSV file
            response = requests.get(self.EXPLOITDB_CSV_URL, timeout=30)
            response.raise_for_status()  # Raise an exception for HTTP errors
            
            # Parse CSV
            csv_data = response.text
            reader = csv.DictReader(io.StringIO(csv_data))
            
            # Filter exploits based on criteria
            results = []
            
            for row in reader:
                # Apply filters
                matches = True
                
                if query and query.lower() not in row.get('description', '').lower():
                    matches = False
                    
                if cve:
                    # Clean CVE ID format
                    cve = cve.upper().replace('CVE-', '').strip()
                    if cve and ('CVE-' + cve) not in row.get('description', ''):
                        matches = False
                
                if platform and platform.lower() not in row.get('platform', '').lower():
                    matches = False
                    
                if exploit_type and exploit_type.lower() not in row.get('type', '').lower():
                    matches = False
                
                # Add to results if all filters match
                if matches:
                    # Extract CVE if available
                    cve_id = ''
                    if 'CVE-' in row.get('description', ''):
                        import re
                        cve_match = re.search(r'CVE-\d{4}-\d{4,}', row.get('description', ''))
                        if cve_match:
                            cve_id = cve_match.group(0)
                    
                    # Format result
                    result = {
                        'exploit_id': row.get('id', ''),
                        'title': row.get('description', '')[:255],  # Limit title length
                        'description': row.get('description', ''),
                        'date_published': row.get('date', ''),
                        'type': row.get('type', ''),
                        'platform': row.get('platform', ''),
                        'source_url': f"https://www.exploit-db.com/exploits/{row.get('id', '')}",
                        'file_path': row.get('file', ''),
                        'cve_id': cve_id,
                        'metadata': row
                    }
                    
                    results.append(result)
                    
                    # Check if we've reached the limit
                    if len(results) >= limit:
                        break
            
            return results
                
        except Exception as e:
            self.logger.error(f"Error searching ExploitDB: {str(e)}")
            return []
    
    def get_exploit_code(self, exploit_id: str) -> str:
        """
        Fetch the actual exploit code from ExploitDB
        
        Args:
            exploit_id: ExploitDB ID
            
        Returns:
            str: Exploit code or empty string on failure
        """
        try:
            # First try to find the file path in the database
            try:
                exploit = Exploit.objects.get(exploit_id=exploit_id, source=self.source)
                if exploit.file_path:
                    file_path = exploit.file_path
                else:
                    # Fetch from CSV to get file path
                    response = requests.get(self.EXPLOITDB_CSV_URL, timeout=30)
                    response.raise_for_status()
                    
                    csv_data = response.text
                    reader = csv.DictReader(io.StringIO(csv_data))
                    
                    file_path = None
                    for row in reader:
                        if row.get('id') == exploit_id:
                            file_path = row.get('file')
                            # Update exploit with file path
                            exploit.file_path = file_path
                            exploit.save()
                            break
                            
                    if not file_path:
                        raise Exception(f"Exploit ID {exploit_id} not found in CSV")
            except Exploit.DoesNotExist:
                # Fetch from CSV
                response = requests.get(self.EXPLOITDB_CSV_URL, timeout=30)
                response.raise_for_status()
                
                csv_data = response.text
                reader = csv.DictReader(io.StringIO(csv_data))
                
                file_path = None
                for row in reader:
                    if row.get('id') == exploit_id:
                        file_path = row.get('file')
                        break
                        
                if not file_path:
                    raise Exception(f"Exploit ID {exploit_id} not found in CSV")
            
            # Check if file_path already starts with 'exploits/' 
            if file_path.startswith('exploits/'):
                # Remove 'exploits/' from the beginning since EXPLOITDB_RAW_URL already has it
                clean_path = file_path[len('exploits/'):]
            else:
                clean_path = file_path
            
            # Now fetch the actual exploit file
            raw_url = f"{self.EXPLOITDB_RAW_URL}/{clean_path}"
            self.logger.info(f"Attempting to fetch exploit code from: {raw_url}")
            response = requests.get(raw_url, timeout=30)
            
            if response.status_code == 200:
                return response.text
                
            # If that fails, try direct ExploitDB download
            alt_url = f"https://www.exploit-db.com/download/{exploit_id}"
            self.logger.info(f"First attempt failed, trying alternate URL: {alt_url}")
            response = requests.get(alt_url, timeout=30)
            
            if response.status_code == 200:
                return response.text
            
            # Try one more method - raw.githubusercontent.com
            github_url = f"https://raw.githubusercontent.com/offensive-security/exploitdb/master/{clean_path}"
            self.logger.info(f"Second attempt failed, trying GitHub URL: {github_url}")
            response = requests.get(github_url, timeout=30)
            
            if response.status_code == 200:
                return response.text
                
            self.logger.error(f"Error fetching exploit code: HTTP {response.status_code} for {raw_url}")
            return ""
            
        except Exception as e:
            self.logger.error(f"Error fetching exploit code: {str(e)}")
            return ""
    
    def import_exploit(self, exploit_data: dict, fetch_code: bool = True) -> Exploit:
        """
        Import exploit data into the database
        
        Args:
            exploit_data: Dictionary containing exploit information
            fetch_code: Whether to fetch and include the exploit code
            
        Returns:
            Exploit object or None on failure
        """
        try:
            # Check if exploit already exists
            exploit_id = exploit_data.get('exploit_id')
            if not exploit_id:
                self.logger.error("Cannot import exploit without ID")
                return None
                
            # Parse date if available
            date_published = None
            if exploit_data.get('date_published'):
                try:
                    date_str = exploit_data['date_published']
                    # Handle different date formats
                    if 'T' in date_str:
                        # ISO format with time
                        date_published = datetime.fromisoformat(date_str.split('T')[0])
                    elif '-' in date_str:
                        # YYYY-MM-DD format
                        date_published = datetime.strptime(date_str, '%Y-%m-%d')
                except Exception as date_error:
                    self.logger.warning(f"Could not parse date: {date_str} - {str(date_error)}")
            
            # Check if exploit exists before creating/updating
            exploit_exists = Exploit.objects.filter(
                exploit_id=exploit_id,
                source=self.source
            ).exists()
            
            # Create or update exploit
            exploit, created = Exploit.objects.update_or_create(
                exploit_id=exploit_id,
                source=self.source,
                defaults={
                    'title': exploit_data.get('title', 'Unknown Exploit'),
                    'description': exploit_data.get('description', ''),
                    'type': exploit_data.get('type', ''),
                    'platform': exploit_data.get('platform', ''),
                    'vulnerability_name': exploit_data.get('vulnerability_name', ''),
                    'cve_id': exploit_data.get('cve_id', ''),
                    'date_published': date_published,
                    'source_url': exploit_data.get('source_url', ''),
                    'file_path': exploit_data.get('file_path', ''),
                    'author': exploit_data.get('author', ''),
                    'verified': exploit_data.get('verified', False),
                    'metadata': exploit_data.get('metadata', {})
                }
            )
            
            # Store the creation state for stats tracking
            exploit._created = created
            exploit._updated = not created
                    
            # Fetch code if requested and not already present
            if fetch_code and not exploit.code and exploit_id:
                code = self.get_exploit_code(exploit_id)
                if code:
                    exploit.code = code
                    exploit.save()
                    
            return exploit
                
        except Exception as e:
            self.logger.error(f"Error importing exploit: {str(e)}")
            return None
    
    def sync_recent_exploits(self, limit: int = 100) -> dict:
        """
        Sync recent exploits from ExploitDB
        
        Args:
            limit: Maximum number of exploits to sync
            
        Returns:
            dict: Statistics about the sync process
        """
        stats = {
            'total': 0,
            'new': 0,
            'updated': 0,
            'failed': 0
        }
        
        try:
            # Get the maximum exploit ID we've already processed
            max_exploit_id = Exploit.objects.filter(source=self.source).aggregate(Max('exploit_id'))['exploit_id__max']
            
            # Add debug logging for max_exploit_id
            self.logger.info(f"Max exploit ID from database: {max_exploit_id}")
            self.logger.info(f"Type of max_exploit_id: {type(max_exploit_id)}")
            
            if max_exploit_id:
                max_exploit_id = int(max_exploit_id)
                self.logger.info(f"Highest exploit ID in database: {max_exploit_id}")
            else:
                max_exploit_id = 0
                self.logger.info("No existing exploits in database, will import all new ones")
            
            # Download the CSV file
            response = requests.get(self.EXPLOITDB_CSV_URL, timeout=30)
            response.raise_for_status()
            
            # Parse CSV
            csv_data = response.text
            reader = csv.DictReader(io.StringIO(csv_data))
            
            # Separate new and existing exploits
            all_exploits = []
            new_exploits = []
            existing_exploits = []
            for row in reader:
                exploit_id_str = row.get('id', '0')
                if not exploit_id_str.isdigit():
                    continue
                    
                exploit_id = int(exploit_id_str)
                if exploit_id > max_exploit_id:
                    # This is a new exploit we don't have yet
                    new_exploits.append(row)
                else:
                    # This is an existing exploit
                    existing_exploits.append(row)

            # Sort by exploit ID (newest first)
            new_exploits.sort(key=lambda x: int(x.get('id', 0)), reverse=True)
            existing_exploits.sort(key=lambda x: int(x.get('id', 0)), reverse=True)

            # Process all new exploits first, regardless of limit
            self.logger.info(f"Found {len(new_exploits)} new exploits to process")
            all_exploits.extend(new_exploits)

            # Then add existing ones up to the limit (if needed)
            if limit > len(new_exploits):
                remaining_slots = limit - len(new_exploits)
                self.logger.info(f"Adding {min(remaining_slots, len(existing_exploits))} existing exploits to reach limit of {limit}")
                all_exploits.extend(existing_exploits[:remaining_slots])
            else:
                self.logger.info(f"Processing only {limit} of {len(new_exploits)} new exploits due to limit")
                all_exploits = all_exploits[:limit]
            
            stats['total'] = len(all_exploits)
            self.logger.info(f"Processing {len(all_exploits)} exploits (limit: {limit})")
            
            # Iterate through exploits with detailed logging
            for row in all_exploits:
                try:
                    exploit_id = row.get('id', '0')
                    
                    # Check if this exploit already exists
                    exists = Exploit.objects.filter(
                        exploit_id=exploit_id,
                        source=self.source
                    ).exists()
                    
                    # Add detailed logging
                    self.logger.info(f"Processing exploit ID: {exploit_id}, already exists: {exists}")
                    
                    # Convert exploit_id to integer for further processing
                    exploit_id = int(exploit_id)
                    is_new = exploit_id > max_exploit_id
                    
                    # Extract CVE if available
                    cve_id = ''
                    if 'CVE-' in row.get('description', ''):
                        import re
                        cve_match = re.search(r'CVE-\d{4}-\d{4,}', row.get('description', ''))
                        if cve_match:
                            cve_id = cve_match.group(0)
                    
                    # Format as exploit data
                    exploit_data = {
                        'exploit_id': row.get('id', ''),
                        'title': row.get('description', '')[:255],  # Limit title length
                        'description': row.get('description', ''),
                        'date_published': row.get('date', ''),
                        'type': row.get('type', ''),
                        'platform': row.get('platform', ''),
                        'source_url': f"https://www.exploit-db.com/exploits/{row.get('id', '')}",
                        'file_path': row.get('file', ''),
                        'cve_id': cve_id,
                        'metadata': row
                    }
                    
                    # Import exploit
                    exploit = self.import_exploit(exploit_data, fetch_code=False)
                    if exploit:
                        if getattr(exploit, '_created', False):
                            stats['new'] += 1
                        else:
                            stats['updated'] += 1
                    else:
                        stats['failed'] += 1
                        
                except Exception as e:
                    self.logger.error(f"Error processing exploit: {str(e)}")
                    stats['failed'] += 1
                    
            # Update source last_update with timezone-aware datetime
            self.source.last_update = timezone.now()
            self.source.save()
            
            return stats
                
        except Exception as e:
            self.logger.error(f"Error syncing exploits: {str(e)}")
            return stats